OpenCV 中有一些预先训练好的级联分类器，可用于检测人脸、脸部特征、人类和其他物体。这些级联分类器以XML 文件的形式存储在源文件的 data 目录下。例如：
C:\opencv\sources\data\haarcascades

### 用 Haar 级联实现人脸检测

经过预先训练的模型可以直接使用。只需用相应的XML文件，创建 cv::CascadeClassifier 类的实例：
```c++
cv::CascadeClassifier faceCascade;
    if (!faceCascade.load("haarcascade_frontalface_default.xml")) {
        std::cout << "Error when loading the face cascade classfier!" << std::endl;
        return -1;
    }
```
<br>

然后用 Haar 特征检测人脸，代码为：
```
faceCascade.detectMultiScale(picture, // 输入图像 
		detections, // 检测结果
		1.1,        // 缩小比例
		3,          // 所需近邻数量
		0,          // 标志位（不用）
		cv::Size(48, 48),    // 检测对象的最小尺寸
		cv::Size(128, 128)); // 检测对象的最大尺寸
    
// 在图像上画出检测结果
for (int i = 0; i < detections.size(); i++)
  cv::rectangle(picture, detections[i], cv::Scalar(255, 255, 255), 2);
```
<br>

### 级联增强分类器

**Haar 特征**

通常认为像素级别的建模方式过于低级，难以鲁棒地表示每个类别的内在特性。选用的模型最好能在多种尺度下描述图像的独特图案。
<br>

Haar 特征定义了包含像素的小型矩形区域，然后用减法运算比较这些矩形。常用的配置有三种，即二矩形特征、三矩形特征和四矩形特征。

![haar](https://github.com/sumpig/OpenCV/blob/master/%E5%AE%9E%E7%94%A8%E6%A1%88%E4%BE%8B/pictures/haar.png)

这些特征可以为任意大小，可以应用于图像上的任何区域。
<br>

构建Haar 模型的步骤是，先选取一定数量的特定类型、尺寸和位置的Haar 特征，然后将它们应用于图像。手动挑选显然是很困难的。因此，我们要采用机器学习方法，为特定的类别选择最适合的特征。
<br>

**构建增强型级联特征**

为了训练针对特定类别的增强型级联分类器，OpenCV 提供了一个软件工具，可以完成全部必需的操作。安装该软件后，在对应的bin 目录下有两个可执行文件，即opencv_createsamples.exe 和 opencv_traincascade.exe。要确保系统的PATH 指向这个目录，以便能在任何位置启动这些工具。
<br>

训练分类器的第一件事就是选取样本。。下面是一个简单的例子，要训练一个能识别停止路标的分类器。选取的一些正样本如下图所示。

![stop](https://github.com/sumpig/OpenCV/blob/master/%E5%AE%9E%E7%94%A8%E6%A1%88%E4%BE%8B/pictures/stop.png)

正样本清单必须存储在一个文本文件中，这里的文件名为stop.txt。文件中包含图像文件名和矩形的坐标：

stop00.png 1 0 0 64 64<br>
stop01.png 1 0 0 64 64<br>
stop02.png 1 0 0 64 64<br>
stop03.png 1 0 0 64 64<br>
stop04.png 1 0 0 64 64<br>
stop05.png 1 0 0 64 64<br>
stop06.png 1 0 0 64 64<br>
stop07.png 1 0 0 64 64<br>

图像文件名后的第一个数字表示图像中正样本的数量，紧接着的两个数字表示包含正样本的矩形的左上角坐标，然后是矩形的宽度和高度。

生成这个文件后，就可以调用提取工具生成正样本文件。
```
opencv_createsamples -info stop.txt -vec stop.vec -w 24 -h 24 -num 8
```
<br>

上述操作的输出文件是stop.vec，文件存储了文本文件中指定的全部正样本。注意，这里的样本尺寸变小了，从原始尺寸(64×64)变为了(24×24)。提取工具会根据指定的尺寸缩放样本。通常情况下，Haar 特征更适合使用较小的模板，但也要看具体的情况。

负样本就是背景图像，即没有包含所需类别的实例（在本例中就是没有停止路标）。但是这些图像应该包含分类器所需的各种内容。没有关于需要多少负样本图像的要求，训练时会从中随机提取。我们用下面的图片作为背景图像。

![negative](https://github.com/sumpig/OpenCV/blob/master/%E5%AE%9E%E7%94%A8%E6%A1%88%E4%BE%8B/pictures/negative.png)

准备好正样本和负样本后，就可以开始训练级联分类器了。调用方法为：

```
opencv_traincascade -data classifier -vec stop.vec
		-bg neg.txt -numPos 9 -numNeg 20
		-numStages 20 -minHitRate 0.95
		-maxFalseAlarmRate 0.5 -w 24 -h 24
```
<br>

在运行过程中，每执行完一个阶段都会输出性能报告。其中需要特别关注的是当前命中率（hit rate，HR）；这个值表示当前被接受的正样本的百分比（即当前被识别为正实例，又称真正样本），这个数值越接近1.0 越好。此外还会有当前虚警率（false alarm rate，FA），它表示被误认为正实例的负样本（又称假正样本），这个数值越接近0.0 越好。每个阶段的每个特征都会显示这两个数值。

分类器的训练结果存储在一个XML 文件里。到这一步，分类器就已经可以使用了！它的用法非常简单，首先装载对应的 XML 文件，构建分类器:
```c++
cv::CascadeClassifier cascade;
    if (!cascade.load("stopSamples/classifier/cascade.xml")) {  // 对应的 XML 文件
        std::cout << "Error when loading the cascade classfier!" << std::endl; 
        return -1; 
    }

    // predict the label of this image
    std::vector<cv::Rect> detections;

    cascade.detectMultiScale(inputImage, // input image 
                             detections, // detection results
                             1.1,        // scale reduction factor
                             1,          // number of required neighbor detections
                             0,          // flags (not used)
                             cv::Size(48, 48),    // minimum object size to be detected
                             cv::Size(128, 128)); // maximum object size to be detected

    std::cout << "detections= " << detections.size() << std::endl;
    for (int i = 0; i < detections.size(); i++)
        cv::rectangle(inputImage, detections[i], cv::Scalar(255, 255, 255), 2);

    cv::imshow("Stop sign detection", inputImage);
```
<br>

用一幅图像测试这个分类器，得到如下结果。

![detection](https://github.com/sumpig/OpenCV/blob/master/%E5%AE%9E%E7%94%A8%E6%A1%88%E4%BE%8B/pictures/detection.png)

**实现原理**

回顾一下支撑增强型级联分类器的两个原理。第一个原理，将多个弱分类器（即基于单一特征的分类器）组合起来，可以形成一个强分类器。

第二个原理，因为机器视觉中的负样本比正样本多得多，所以可以把分类过程分为多个阶段，以提高效率。前面的阶段可以快速排除掉明显不符合要求的实例，后面的阶段可以处理更复杂的样本，进行更精确的判断。

下面将基于这两个原理解释增强型级联学习算法，并使用一种最常用的增强类型，即 **AdaBoost**。此外，还将对 **opencv_traincascade** 工具的部分参数进行说明。

利用 Haar 特征构建弱分类器。每应用一个 Haar 特征（指定类型、大小和位置），就得到一个特征值。只要找到根据特征值区分负实例和正实例的最佳阈值，就得到了一个单一分类器。

为找到这个最佳阈值，就需要一批正样本和负样本（opencv_traincascade 的参数 **-numPos** 和 **-numNeg** 分别表示所用正样本和负样本的数量）。

因为可用的Haar 特征非常多，所以需要逐个检查并选取最适用于区分样本的特征。显然，这种非常基本的分类器可能会出错（即对一些样本进行错误分类），因此需要构建多个分类器；每当要寻找分类效果最好的新Haar 特征时，就增加一个分类器。在迭代时要重点关注被错误分类的样本，评价分类性能时要给这些样本更高的权值。这样就得到了一批单一分类器，然后把这些弱分类器进行加权累计（性能较好的分类器获得更高的权值），继而构建一个强分类器。采用这种方法将数百个单一特征组合起来，即可得到一个性能良好的强分类器。

级联分类器的核心思想是在早期排除掉不符合要求的样本。我们不希望在构建强分类器时使用大量的弱分类器，而是要找到只用少量 Haar 特征的极小型分类器，以便快速排除明显的负样本，并保留全部正样本。

AdaBoost 的典型形式就是通过统计假负样本（被看作负样本的正样本）和假正样本（被看作正样本的负样本）的数量，使分类错误的总数最小化。

这种情况下，需要大多数（最好全部）正样本能被正确分类，以降低假正率。好在AdaBoost 是可以调节的，能使真正样本的可靠性更高。因此，训练级联分类器的每个阶段都必须设置两个约束条件：

最小命中率和最大虚警率，可以通过在 opencv_traincascade 中设置参数 **-minHitRate**（默认为0.995）和 **-maxFalseAlarmRate**（默认为0.5）实现。

只有满足了这两个性能指标，才会在这个阶段加入 Haar 特征。设置的最小命中率必须足够大，以确保正实例能顺利进入下一阶段。注意，如果一个阶段排除了正实例，这个错误就无法修复。因此，为了避免分类器的生成过程太复杂，要把最大虚警率设置得高一点，否则在训练阶段就需要大量 Haar 特征才能满足性能指标，这违背了早期排除和快速计算的初衷。

一个好的级联分类器，前期阶段的特征数要很少，到后期再逐步增加。在 opencv_traincascade 工具中，用参数 **-maxWeakCount**（默认值100）设置每个阶段的最大特征数，用 **-numStages**（默认值20）设置阶段的个数。

每开启一个新的训练阶段，都要选取新的负样本，这些负样本是从背景图中提取的。这里的难点在于，要找出通过了前面所有阶段的负样本（即被错误地认作正样本）。完成的阶段越多，找出这种负样本的难度就越大。正因为如此，背景图的种类一定要多，这一点很重要。接着，可以从这些难以分类的样本（因为它们与正样本非常相似）中提取出小块。

另外需要注意，如果在一个阶段中，在不需要增加新特征的情况下就能满足两个性能指标，那就在此时停止级联分类器的训练（这个分类器已经能够使用；也可以加入更难的样本，重新训练）。反之，如果这个阶段无法满足性能指标，也应该停止训练；这时应该降低性能指标，重新训练。

很明显，一个包含n 个阶段的级联分类器的整体性能至少要好于 minHitRate^n 和 maxFalseAlarmRate^n。这是因为在级联分类器中，每个阶段都是在前面阶段的基础上构建的。例如 opencv_traincascade 使用默认参数时，级联分类器的精度（命中率）预计为 0.99520，虚警率预计为 0.520。这意味着 90% 的正实例会被正确地标识，0.001% 的负样本会被错误地标识为正样本。注意，有少数正样本会随着训练阶段的推进而丢失，因此一定要提供比每个阶段所需数量更多的正样本。在上述例子中，numPos 应该设为可用正样本数量的 90%。

训练时该使用多少样本？这个问题很重要。虽然具体的数字很难确定，但是很明显，正样本的数量必须足够多，以覆盖识别对象的各种外观。背景图也应该采用相关的图片，比如在识别停止路牌的例子中，我们选用了城市背景的图片，因为这种地方很可能出现路牌。根据经验，通常采用 numNeg= 2 \* numPos，但这取决于具体情况。

最后，Haar 特征也可以用其他特征来构建，例如局部二值模式，或者方向梯度直方图。在 opencv_traincascade 中使用 **-featureType**，可以选用其他类型的特征。
