> OpenCV 提供了很多人脸识别方法，它们都是通用类 **cv::face::FaceRecognizer** 的子类。
<br>

### cv::face::LBPHFaceRecognizer
基于最邻近分类法，使用的图像模型基于局部二值模式（local binary pattern，LBP）特征
<br>

调用 cv::face::LBPHFaceRecognizer 的静态函数 **create** 以创建它的实例：
```c++
cv::Ptr<cv::face::FaceRecognizer> recognizer =
    cv::face::createLBPHFaceRecognizer(1, // LBP 模式的半径
        8, // 使用邻近像素的数量
        8, 8, // 网格大小
        200.8); // 最邻近的距离阈值
```
<br>

接着要向识别器输入一批参考人脸图像，具体为提供两个向量，一个存放人脸图像，另一个存放对应的标签。下面是一个简化的例子，只提供两个人，每人两幅图像。调用训练方法的代码为：
```c++
// 参考图像和标签的向量
std::vector<cv::Mat> referenceImages;
std::vector<int> labels;
// 打开参考图像
referenceImages.push_back(cv::imread("face0_1.png",
                          cv::IMREAD_GRAYSCALE));
labels.push_back(0); // 编号为0 的人

referenceImages.push_back(cv::imread("face0_2.png",
                          cv::IMREAD_GRAYSCALE));
labels.push_back(0); // 编号为0 的人

referenceImages.push_back(cv::imread("face1_1.png",
                          cv::IMREAD_GRAYSCALE));
                          
labels.push_back(1); // 编号为1 的人
referenceImages.push_back(cv::imread("face1_2.png",
                          cv::IMREAD_GRAYSCALE));
labels.push_back(1); // 编号为1 的人

// 通过计算LBPH 进行训练
recognizer->train(referenceImages, labels);
```

> 最好把图像归一化，使关键的面部特征处于标准位置。

输入一幅图像，它就可以计算出图中人脸对应的人员编号：
```c++
// 识别图像对应的编号
recognizer->predict(inputImage, // 人脸图像
                    predictedLabel, // 识别结果
                    confidence); // 置信度
```
<br>

置信度数值越小，识别结果越可信。

<br>

### 原理

**LBP 特征**

它是把每个像素转换为一个二进制数模型，表示邻近位置的图像强度模式。规则：将一个局部像素与它的每个邻近像素进行比较，如果它的值大于邻近像素，就把对应的位设为0，否则设为1。最常用的做法是将每个像素与它的 8 个邻近像素做比较，得到 8 位模式，例如下面的局部模式：

| 87   | 98   | 17   |
| ---- | ---- | ---- |
| 21   | 26   | 89   |
| 19   | 24   | 90   |

应用上述规则，得到以下二进制数值：

| 1    | 1    | 0    |
| ---- | ---- | ---- |
| 0    |      | 1    |
| 0    | 0    | 1    |

从左上角的像素开始顺时针方向提取，得到二进制串11011000，用它表示中心的像素。对每个像素计算其LBP 字节，即可得到完整的8 位LBP 图像。这一步由下面的函数实现：
```c++
// 计算灰度图像的局部二值模式
void lbp(const cv::Mat &image, cv::Mat &result) {

	assert(image.channels() == 1); // input image must be gray scale

	result.create(image.size(), CV_8U); // 必要时分配空间

	for (int j = 1; j<image.rows - 1; j++) { // 逐行处理（除了第一行和最后一行）

		const uchar* previous = image.ptr<const uchar>(j - 1); // previous row
		const uchar* current  = image.ptr<const uchar>(j);	   // current row
		const uchar* next     = image.ptr<const uchar>(j + 1); // next row

		uchar* output = result.ptr<uchar>(j);	// output row

		for (int i = 1; i<image.cols - 1; i++) {

			// 构建局部二值模式
			*output =  previous[i - 1] > current[i] ? 1 : 0;
			*output |= previous[i] > current[i] ?     2 : 0;
			*output |= previous[i + 1] > current[i] ? 4 : 0;

			*output |= current[i - 1] > current[i] ?  8 : 0;
			*output |= current[i + 1] > current[i] ? 16 : 0;

			*output |= next[i - 1] > current[i] ?    32 : 0;
			*output |= next[i] > current[i] ?        64 : 0;
			*output |= next[i + 1] > current[i] ?   128 : 0;
			
			output++; // next pixel
		}
	}

	// 将未处理的像素设为0
	result.row(0).setTo(cv::Scalar(0));
	result.row(result.rows - 1).setTo(cv::Scalar(0));
	result.col(0).setTo(cv::Scalar(0));
	result.col(result.cols - 1).setTo(cv::Scalar(0));
}
```
<br>

再来看 cv::face::LBPHFaceRecognizer 类，它的 create 方法的前两个参数分别指定了邻域的大小（半径，单位为像素）和维度（圆上的像素数量，可用于插值）。
把得到的 LBP 图像分割成一个网格，网格大小由 create 方法的第三个参数指定。
对网格上的每个区块构建直方图。
最后，把这些直方图的箱子数组合成一个大的向量，得到全局图像模型。
对于 8×8 的网格，计算 256-箱子直方图，得到 16 384 维的向量。
<br>

cv::face::LBPHFaceRecognizer 类的 train 函数对每个参考图像都用上述方法计算出一个很长的向量。每个人脸图像都可看作是高维空间上的一个点。识别器用predict 方法得到一个新图像后，就能找到与它距离最近的参考点。
该参考点对应的标签就是识别结果，它们的距离就是置信度。这就是最近邻分类器的基本原理。
还有一个因素需要考虑：如果输入点与最近的参考点之间的距离太远，就说明它其实并不属于任何类别，那么“距离太远”的判断标准是什么？这由cv::face::LBPHFaceRecognizer 的create 方法的第四个参数决定。


1
